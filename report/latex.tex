\documentclass[times, twocolumn]{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{float}
\usepackage{pgfplots}
\usepackage{subcaption}
\usepackage{comment}
\usepackage[a4paper, total={7in, 9in}]{geometry}
\usepackage{biblatex}

\addbibresource{mybib.bib}

\title{Spotify Tracks Genre Classification}
\author{Nabeha Barkatullah, Mia Striebeck, Laksha Karthikeyan, Carson Chiem, Shuzo Naruse}
\date{May 20, 2024}

\begin{document}
\maketitle

\newpage
% abstract
\begin{abstract}
Discovering new music that fits within your music taste is time-consuming and difficult. On top of there being an abundance of music to sift through, finding songs from the bulk that you actually enjoy listening to can go either way. With this project, we aim to utilize a Spotify dataset to build a model to classify songs under genres, with the potential of being part of a song recommendation system. Using the attributes from the dataset, such as the relevant music listening patterns and classification of songs, we will predict the genre a song falls under. Our goal is to build a classification model that predicts a song’s genre based on user-inputted track features.
\end{abstract}
\section{Introduction}
With music production becoming increasingly accessible, music platforms have subsequently become saturated with new music. For newer or more niche artists, being discovered among a sea of other songs and competing within the platform’s algorithm. On the other hand, for users looking for new music, breaking beneath the surface of more popular songs within genres they may enjoy can prove to be difficult and sifting through songs to curate their music profile is time consuming and frustrating when you are not exactly sure what you are looking for. 

This project is posed to be a part of a larger music recommendation system; this aspect of the system encompasses a machine learning driven genre classification model using the K-nearest neighbors method. To narrow down the scope of this project, we have our tool limited to music on Spotify’s platform for data feature accessibility— music uploaded to Spotify has an associated song ID, among other descriptive features about the song. Using Spotify music data sourced from Kaggle, a machine learning model based on K-nearest neighbors was trained and connected to the front end of a web based GUI.  In terms of the front end interaction, the user is able to navigate through our GUI which searches though a Spotify dataset in order to input a song from search and predict the genre it belongs to. As a part of a larger product, this model would be used in tandem with other tools to fine tune a recommendation system based upon other aspects apart from genre. 

For the task of genre classification, machine learning appeared to be the obvious approach due to the apparent degree of subjectivity of the task— the classification of a song into a genre is not always a clear choice but a decision can be made based upon patterns in music. ML is especially useful in this case where genre patterns can help form clearer decision boundaries. Additionally songs often do not belong to one single genre— more often than not they belong to multiple genres such as “Pop, Rock, EDM”, “Indie, Pop”, “Country, Jazz”. With this in mind, utilizing K-nearest neighbors as an ML approach provides a robust solution for the proposed task of genre classification as it provides a cluster of genres that most closely fit the inputted song.  

% background
\section{Background}
The purpose of this project is to lay the foundation for a robust music recommendation system outside of popular platforms music boosting algorithms. While effective, music algorithms within the app have a tendency to push surface level music within genres, often excluding more niche songs within genres— prioritizing breadth over depth in recommendations. While recreational in nature, utility for this tool was immediately recognized among our group as a result of music being so pervasive through the college student experience. 

This project was developed with respect to other existing recommendation systems in our literature review. Spotify has publicly provided open source music data sets with 20 features for use online through Kaggle, as well as web tools for developers. A machine learning approach was integrated into the goals of this project, with methods such as K-NN, random forest, and others considered. 

The use of the  K-NN algorithm was motivated primarily by the targeted functionality of the tool and the adaptability of K-NN as a method. Assigning clusters of applicable genres to a user inputted song seemed relevant for real-life usage since songs are not limited to a single genre. 
%literature review
\section{Literature Review}
Many previous works have utilized machine learning techniques to classify music by genre. R. Prajwal and Sharma et al. (2021) built multiple classification models based on features extracted from audio samples, such as spectral centroid (the weighted mean of the sound frequencies) and the shape of sound signals~\cite{Singhal2022}. They conducted feature selection and hyperparameter tuning using GridSearchCV and RandomizedSearchCV, optimizing the k value for k-NN to maximize accuracy~\cite{Singhal2022}. The models implemented included k-Nearest Neighbors (KNN), Support Vector Machine (SVM), Logistic Regression, and Random Forests~\cite{Singhal2022}. SVM achieved the highest accuracy of 76.4\%, followed by Random Forests with 69.6\%, KNN with 66.4\%, and Logistic Regression with 67.2\%, all after hyperparameter tuning~\cite{Singhal2022}.\\

While their dataset utilized technical audio features such as zero-crossing rate and mel-frequency cepstrum coefficients, our dataset includes numerical measures of musical elements and human interpretations of music, such as the mode, which describes the mood of a song. This is more similar to the work by Rahul Singhal and Shruti Srivatsan, who noted that classification models using Extreme Gradient Boosting and Random Forest performed the best compared to traditional ML approaches~\cite{prajwal2021music}. In particular, a hyperparameter-tuned Random Forest classifier achieved high accuracy and F1-score~\cite{prajwal2021music}.\\

Given that our dataset encompasses features like popularity, acousticness, and danceability, we wanted to explore how Random Forest would perform for our model. The KNN algorithm is noted for its simplicity in terms of workings and calculations. It offers flexibility for various modifications to overcome limitations, enhance accuracy, and increase its applicability to a wider variety of datasets. KNN's adaptability allows for performance improvements through optimizing the k parameter, refining distance calculations, and adding weights to different data points.

\section{Dataset Description and EDA}
\subsection{Dataset Description}
The original Kaggle dataset contains data on Spotify songs from over 125 genres, with each song having associated features related to identification of each track, audio characteristics, or popularity and genre classifications. The original set contained around 114k data points (songs/tracks) condensed in a CSV format, with 20 features, which are track id, artist name, album name, track name, popularity, duration (ms), explicit, danceability, energy, key, loudness, mode, speechiness, acousticness, instrumentalness, liveness, valence, tempo, and time signature. Popularity is the ranking of each song on a scale of 1 to 100, duration of the track is in milliseconds (ms), explicit is a boolean value, stating if a song contains explicit lyrics, danceability is a level, from 0 to 1, of a song being considered suitable for dancing, energy is a measure, from 0 to 1, of intensity, key is in regards to overall musical pitch, loudness is measured in decibels (dB), mode indicates if the track is on a major or minor scale (1 or 0), speechiness measures, from 0 to 1, the level of spoken words in a track, acousticness is a measure, from 0 to 1, of instruments used without electrical amplification, instrumentalness is a measure, from 0 to 1, of a track containing vocals, liveness is the likelihood of a song being performed in front of an audience, valence measures the interpretation of a song as positive or negative, tempo is the speed of a track, measured in beats per minute (BPM), and time signature indicates the number of beats in each measure of the piece. All are continuous variables, except for track id, artist name, album name, track name, explicit, popularity and track genre, which are categorical. Popularity is particularly ordinal categorical, as tracks are assigned a ranking of popularity. 

In pre-processing the data, we checked for duplicate rows and missing values. 32,656 rows were dropped, as they were each identified as having the same track name and artist as an another track. The remaining rows of distinct tracks were filtered to identify missing values for each feature, which identified one track having 3 missing values. Furthermore, the genre feature originally contained 125 classes, however, as many genres were more specific sub-genres, these sub-genres were grouped under their respective overall genres. For instance, tracks with the sub-genres "emo," "punk," and "garage," were all re-classified under the genre "punk-rock." This allowed for greater accuracy of genre classification, with reduced complexity and risk of overfitting, as the model would be less likely to fit too closely to the data of these more specific sub-genres, and a larger sample size within the overall genre would allow for greater accuracy. The dataset was ultimately filtered to only contain the 10 most popular genres, removing the rows of all other genres. Thus, the resulting cleaned dataset contained 81,344 rows of distinct tracks.

\subsection{Exploratory Data Analysis}
We conducted exploratory data analysis in order to further investigate the distributions of the features in our dataset and their correlations with each other, to identify potential presence of multicollinearity or irregularities, to help perform feature selection and identify the top 10 most frequent artists and genres in this dataset.

Figure \ref{graph:dists} shows frequency distributions of the features, showing that the danceability and tempo features have nearly normal distributions, while the distribution of loudness is left-skewed, and acousticness, speechiness, liveness are right-skewed. This signifies that while most of the songs in this dataset are moderately loud, there are some that have particularly low levels of loudness, that makes the distribution skew to the right. Similarly, acousticness, speechiness and liveness have similar levels among most of the songs, although there are some outlier songs with significantly higher levels of acousticness, speechiness and liveness that cause these distributions to skew to the right.

% adding Figure 1 - image of feature distributions
\begin{figure}[H]
    \centering
    \includegraphics[width=0.55\textwidth]{report_pics/feature_dists_new.png}
    \caption{Frequency distributions of the continuous track features, which have been scaled using z-score normalization.}
    \label{graph:dists}
\end{figure}

Box plots were used to further examine the distributions and identify outliers, as seen in Figure \ref{Boxplots}, which maps the distributions for the ordinal categorical predictor variable popularity, and every continuous predictor variable, which include duration, tempo, loudness, acousticness, danceability, energy, instrumentalness, liveness, speechiness and valence. From this visualization, it is evident that popularity, acousticness, energy and valence have no outliers, while all other features do, although it is expected that popularity contains no outliers, as these are ranked values of a pre-determined range. The presence of outliers is reasonable as it merely shows the diversity of the songs in our dataset, and ultimately, the variety in levels of these features is what characterizes the different music styles that allow a song to be categorized under a certain genre.
% adding Figure 2 - boxplots
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth, height=10cm]{report_pics/feat_boxplots_new.png}
    \caption{Box plots depicting the distributions of the continuous features in our dataset, scaled using z-score normalization.}
    \label{Boxplots}
\end{figure}
Figure \ref{heatmap} displays the correlations between the continuous predictor variables in the dataset. It shows a significant positive correlation between energy and loudness, and that acousticness is significantly, negatively correlated with both loudness and energy. Further, danceability and valence appear to have a weak positive correlation, and instrumentalness and loudness have a weak negative correlation. Although the significant correlations between multiple features, such as between acousticness with loudness and energy, indicates multicollinearity, it is slight and therefore not likely to have a significant impact on the results of our classification model.
\begin{figure}[H]
    \centering
    \textbf{Pearson's Correlation Heatmap of Relevant Features}
    \includegraphics[width=1.0\linewidth]{report_pics/corr_heatmap_new.png}
    \caption{The Pearson's correlation heatmap depicts the pairwise correlations between the 11  continuous features that are relevant to the characteristics of each track, where a value less than 0 indicates negative correlation, and a value greater than 0 indicates positive correlations between the features.}
    \label{heatmap}
\end{figure}

Figure \ref{top10} depicts the 10 most frequent artists and the top 10 most frequent genres that are present in the cleaned dataset. The 10 genres with the greatest frequency of tracks in this dataset are Electronic Dance Music (EDM), punk-rock, pop, rock, alt-rock, rock, acoustic, k-pop, classical, piano, and hip-hop. 

% adding Figure 4 - top 10 most frequent
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{report_pics/top_genres.png}
    \caption{Top 10 artists and genres}
    \label{top10}
\end{figure}

These results provided valuable insights into the distributions and spread of our individual features, as well as the varying frequency of tracks for all the different genres. This was useful information in choosing methods that would be best suitable for the characteristics of the dataset, and evaluating the performance of our models.

\section{Proposed Methodology}
In order to build a classification model to classify the genre of a track based on the predictor variables related to audio characteristics, our modeling approach entailed identifying techniques that would work well for multi-class classification, as our dataset contains multiple possible genres. We examined the performance of K-nearest neighbors clustering and Random Forest models.

\section{Experimental Results and Evaluation}
\subsection{Model Performances}
\subsubsection{Assumption}
\begin{itemize}
    \item \textbf{Experiment Setup}: The performance of the K-NN model was evaluated by varying the number of neighbors (k) to 20, 50, 60, 70, and 100 on a dataset containing approximately 250,000 entries.
    \item \textbf{Performance Metrics}: The accuracy, precision, recall, and F1 score of each model were compared based on the confusion matrix.
    \item \textbf{Genre Analysis}: The dataset includes 9 genres. Macro averages are compared for each genre. It is important to note that the micro averages for accuracy, precision, recall, and F1 score will be the same. There is a significant disparity in the sample sizes of each genre, with differences up to six times, suggesting that macro averages might not accurately reflect the model's performance.
\end{itemize}

\subsubsection{Result and Analysis}
The full results are presented in Table \ref{table:result}.
\begin{table}
    \begin{center}
        \begin{tabular}{|c||c|c|c|c|c|} \hline
            n & accuracy & precision & recall & f1 & time \\ \hline
            20  & 0.5301 & 0.5266 & 0.5240 & 0.5233 & 160.1 \\
            50  & 0.5335 & 0.5314 & 0.5235 & 0.5249 & 186.7 \\
            60  & 0.5340 & 0.5323 & 0.5231 & 0.5250 & 200.1 \\
            70  & 0.5335 & 0.5316 & 0.5218 & 0.5237 & 207.2 \\
            100 & 0.5333 & 0.5319 & 0.5197 & 0.5224 & 216.1 \\
            \hline
        \end{tabular}
        \caption{Result. \textit{precision}, \textit{recall}, and \textit{f1} are the macro-averages, respectively. \textit{time} is the time taken to train the model for each number of neighbors.}
        \label{table:result}
    \end{center}
\end{table}
\begin{itemize}
    \item \textbf{Accuracy}: Shown in Figure \ref{fig:accuracy}, the accuracy varies from 0.5301 (k=20) to 0.5340 (k=60). This small range of variation (approximately 0.004) suggests that the model's performance is relatively stable across different values of \verb|n_neighbors|. The accuracy increased as the value of \verb|n_neighbors| approached 60, after which it started to decline. This indicates that the optimal number of neighbors for maximizing accuracy lies around 60.
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.46\textwidth]{figure/result/KNN_Accuracy.png}
        \caption{Accuracy}
        \label{fig:accuracy}
    \end{figure}
    
    \item \textbf{Precision (Macro)}: Shown in Figure \ref{fig:precision}, the macro-averaged precision ranges from 0.5266 (k=20) to 0.5323 (k=60). This suggests that the model's precision across different classes is relatively consistent. Precision values improved with the increase in the number of neighbors.
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.46\textwidth]{figure/result/KNN_Precision_Macro.png}
        \caption{Macro Average of Precision}
        \label{fig:precision}
    \end{figure}

    \item \textbf{Recall (Macro)}: Shown in Figure \ref{fig:recall}, the macro-averaged recall ranges from 0.5197 (k=100) to 0.5240 (k=20). This indicates that the model's recall across different classes does not vary significantly. In contrast to precision, recall values exhibited a downward trend as the number of neighbors increased. This inverse relationship between precision and recall is typical due to their inherent trade-off.
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.46\textwidth]{figure/result/KNN_Recall_Macro.png}
        \caption{Macro Average of Recall}
        \label{fig:recall}
    \end{figure}
    
    \item \textbf{F1 Score (Macro)}: Shown in Figure \ref{fig:f1}, the macro-averaged F1 score ranges from 0.5224 (k=100) to 0.5250 (k=60), reflecting a balanced performance across different classes. The F1 score, which balances precision and recall, mirrored the trend observed in accuracy. It increased towards \verb|n_neighbors| = 60 and decreased beyond this point. Thus, the optimal F1 score is also achieved at \verb|n_neighbors| = 60.
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.46\textwidth]{figure/result/KNN_F1_Macro.png}
        \caption{Macro Average of F1 Score}
        \label{fig:f1}
    \end{figure}
\end{itemize}

\subsection{Model Implications}
\subsubsection{Best Model Selection}
Based on the analysis, \verb|n_neighbors| = 60 was determined to be the optimal number of neighbors for the KNN model. This setting provided the best balance between precision and recall, as evidenced by the F1 score. Although recall decreases with increasing \verb|n_neighbors|, this might be attributed to the inherent characteristics of the genre classification task, where songs do not cluster tightly within genres. This suggests a lack of consistent features within each genre. Given the nature of music genre classification, where false positives are less critical, high precision is of greater importance. Therefore, the model's ability to correctly identify true positives (high precision) is prioritized over the coverage of all relevant instances (recall).

\section{Discussion}
When evaluating the performance of Random Forest and k-Nearest Neighbors for classifying song genre based on individual characteristics of the song, the resulting model indicated that it is possible to predict the genre of a song based on these features, however there was a consistently low accuracy across the attempted models. Although the model evaluation metrics indicate that Random Forest had a higher accuracy, since both models had relatively low accuracy, we decided that k-Nearest Neighbors would be the ideal choice, as it would output more than one genre prediction for each song. In regards to potential improvements, one limiting factor that we found with our dataset was that genres of Spotify songs are generally assigned based on the artist, rather than the song itself. For example, every song by Olivia Rodrigo is listed as pop, despite songs such as “good 4 u” and “brutal” being largely classified as alternative rock or pop-punk by the media and mainstream audience. This adversely affected the model during the training process since track features correlated with rock songs might be labeled as pop, thus potentially making both rock and pop predictions less accurate during testing. Instead, using a dataset where genre is assigned to individual songs, would increase model accuracy, as the classified genre would be more accurately based on these features specific to the song. We would also explore less computationally expensive methods, as although we found k-Nearest Neighbors to be an effective model for this multi-class classification, it became increasingly time-consuming to process the large training data set, requiring a large k parameter. 

\section{Conclusion}



\section{Github link and Project Roadmap}

\section{Works Cited}
\printbibliography


\end{document}
